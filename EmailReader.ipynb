{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering Step "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps Taken: \n",
    "1. Download sample application emails from gmail account as an eml(email) object\n",
    "2. Convert eml object to an array and then convert to dataframe to store as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import eml_parser\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# # Note : Converts email objects to csv(not needed was used for initial data gathering)\n",
    "# import numpy as np\n",
    "# path = os.getcwd()+'/emails'\n",
    "# emailsArray = [];\n",
    "# for filename in glob.glob(os.path.join(path, '*.eml')):\n",
    "#     with open(os.path.join(os.getcwd(), filename), 'rb') as f: # open in readonly mode\n",
    "#         raw_email = f.read()\n",
    "#         ep = eml_parser.EmlParser(include_raw_body=True)\n",
    "#         parsed_eml = ep.decode_email_bytes(raw_email)\n",
    "#         emailsArray.append(parsed_eml['body'][0]['content'])\n",
    "\n",
    "# columns = [\"Message\"]\n",
    "# df = pd.DataFrame(data=emailsArray, columns=columns)\n",
    "# df[\"Status\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[0].Message\n",
    "# df.to_csv (r'./sampleEmails.csv', index = False, header=True)\n",
    "# After cleaning up csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read excel into a dataframe(used excel instead of csv)\n",
    "2. Then clean up each message, removing all stopwords as well as some other ones(including HTML formatted tags)\n",
    "3. Use train_test_split to split up the training data and create the Naive Bayes Classifer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Status</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello Akhil,\\n\\n\\n\\n Thank you for your intere...</td>\n",
       "      <td>Applied</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;div&gt;Dear Akhil,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Than...</td>\n",
       "      <td>Applied</td>\n",
       "      <td>Impossible Foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi Akhil,\\n\\n\\n\\nThanks so much for submitting...</td>\n",
       "      <td>Applied</td>\n",
       "      <td>Stripe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;div&gt;Hi Akhil,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thank ...</td>\n",
       "      <td>Applied</td>\n",
       "      <td>Scratch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi Akhil,\\n\\nåÊ\\n\\nThank you for your interest...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>GRAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Hello - you are apparently my tutor for CS cou...</td>\n",
       "      <td>Junk</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>This is an automatically generated e-mail from...</td>\n",
       "      <td>Junk</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>\\nThanks for choosing Apple.\\nHi Akhil,\\n\\nIt’...</td>\n",
       "      <td>Junk</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Discover short- and long-term investment oppor...</td>\n",
       "      <td>Junk</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Hi Akhil,\\n\\nHow can you cut through the compe...</td>\n",
       "      <td>Junk</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Message    Status  \\\n",
       "0   Hello Akhil,\\n\\n\\n\\n Thank you for your intere...   Applied   \n",
       "1   <div>Dear Akhil,</div><div><br></div><div>Than...   Applied   \n",
       "2   Hi Akhil,\\n\\n\\n\\nThanks so much for submitting...   Applied   \n",
       "3   <div>Hi Akhil,</div><div><br></div><div>Thank ...   Applied   \n",
       "4   Hi Akhil,\\n\\nåÊ\\n\\nThank you for your interest...  Rejected   \n",
       "..                                                ...       ...   \n",
       "74  Hello - you are apparently my tutor for CS cou...      Junk   \n",
       "75  This is an automatically generated e-mail from...      Junk   \n",
       "76  \\nThanks for choosing Apple.\\nHi Akhil,\\n\\nIt’...      Junk   \n",
       "77  Discover short- and long-term investment oppor...      Junk   \n",
       "78  Hi Akhil,\\n\\nHow can you cut through the compe...      Junk   \n",
       "\n",
       "             Company  \n",
       "0              Tesla  \n",
       "1   Impossible Foods  \n",
       "2             Stripe  \n",
       "3            Scratch  \n",
       "4              GRAIL  \n",
       "..               ...  \n",
       "74              None  \n",
       "75              None  \n",
       "76              None  \n",
       "77              None  \n",
       "78              None  \n",
       "\n",
       "[79 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read from Excel sheet with Message, Status and Company\n",
    "df2 = pd.read_excel('./sampleEmailsWithCompanies.xlsx')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def showOnlyKeyWords(mess):\n",
    "    # Remove all punctuation from the messages section\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    nopunc.split()\n",
    "    # Remove stop words including some custom ones like hello and Akhil\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    newStopWords = ['hello','akhil', 'thank', 'div', 'br', 'thanks', 'hi']\n",
    "    stopwords.extend(newStopWords)\n",
    "    clean_mess = [word for word in nopunc.split() if word.lower() not in stopwords]\n",
    "    return clean_mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [interest, joining, team, Tesla, We‰Ûªve, rece...\n",
       "1    [divDear, AkhildivdivbrdivdivThanks, applying,...\n",
       "2    [much, submitting, application, Backend, API, ...\n",
       "3    [divHi, AkhildivdivbrdivdivThank, applying, ro...\n",
       "4    [åÊ, interest, joining, GRAIL, sharing, vision...\n",
       "Name: Message, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Message'].head(5).apply(showOnlyKeyWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8dfab50c90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.head()\n",
    "df2['Status'].value_counts().plot(kind=\"bar\")\n",
    "#Unfortunately at this time I only have about 100 data set of applied, rejected and non application mail(couldnt import more because a lot had sensitive data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df2['Message']\n",
    "y = df2['Status']\n",
    "comp = df2['Company']\n",
    "Xcomp = df2['Message']\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(X)\n",
    "Xcomp = cv.fit_transform(Xcomp)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1)\n",
    "# print(type(X))\n",
    "\n",
    "\n",
    "XComp_train, XComp_test, y_compTrain, y_compTest = train_test_split(Xcomp, comp,test_size=0.2)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nbComp = MultinomialNB()\n",
    "nb.fit(X_train,y_train)\n",
    "nbComp.fit(XComp_train, y_compTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google API(Gmail) Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Google's API Library and following their documentation, we start the OAuth 2 process that is required. \n",
    "\n",
    "In order to get this app working you will need to enable your account to be able to use Gmail API and download and save the generated credentials json as credentials.json. In addition, if running from a local server will need to add your port in this code as well as on Google API's dashboard(ie : add \"localhost:8080/\" to redirect URI)\n",
    "\n",
    "Reccomend using Chrome, and on first run will cause you to sign in to gmail using your browser. After the token.json file has been generated in your directory, the token will autorefresh so no need to keep signing in. \n",
    "\n",
    "The rest of the code will handle reading your emails and running it thru the model to predict if the email message indicates if you have been rejected, or just applying or just a random email(this specific one needs more sample data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import base64\n",
    "import re\n",
    "import unpaddedbase64\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import os.path\n",
    "\n",
    "# these are just for authenticating\n",
    "import google.oauth2.credentials\n",
    "from google_auth_oauthlib.flow import Flow\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
    "\n",
    "creds = None\n",
    "# The file token.json stores the user's access and refresh tokens, and is\n",
    "# created automatically when the authorization flow completes for the first\n",
    "# time.\n",
    "if os.path.exists('token.json'):\n",
    "    creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "# If there are no (valid) credentials available, let the user log in.\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            'credentials.json', SCOPES)\n",
    "#         Define port(will have to match redirect URI for local instance)\n",
    "        creds = flow.run_local_server(port=8080)\n",
    "    # Save the credentials for the next run\n",
    "    with open('token.json', 'w') as token:\n",
    "        token.write(creds.to_json())\n",
    "service = build('gmail', 'v1', credentials=creds)\n",
    "results = service.users().messages().list(userId='me').execute()\n",
    "messageIds = results['messages']\n",
    "listOfIds = [];\n",
    "listOfMessages = []\n",
    "senderOfMessages = [];\n",
    "for messageId in messageIds:\n",
    "    listOfIds.append(messageId['id'])\n",
    "    \n",
    "for idMail in listOfIds:\n",
    "    emails = service.users().messages().get(userId='me', id=idMail, format=\"full\").execute()\n",
    "    senderOfMessages.append(emails['payload']['headers'][-3]['value'])\n",
    "    data = emails['payload']['parts'][0]['body']['data']\n",
    "    encodedData = unpaddedbase64.decode_base64(data)\n",
    "    s = encodedData.decode('UTF-8')\n",
    "    listOfMessages.append(s)\n",
    "        \n",
    "# print(listOfMessages)\n",
    "\n",
    "statusResult = nb.predict(cv.transform(listOfMessages))\n",
    "\n",
    "\n",
    "# In the sample the sender has a lot of my email(because email was forwarded so header containers sender not original sender) \n",
    "\n",
    "finalDf = pd.DataFrame({'status':statusResult, 'sender':senderOfMessages, 'message':listOfMessages})\n",
    "finalDf\n",
    "\n",
    "\n",
    "# If you want to save the results, unccoment the code below\n",
    "\n",
    "\n",
    "# finalDf.to_csv(r'./jobResults.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As You Can see some of the predicitions still need to be worked on as more data is used we can increase the accuracy. However this code will read email messages from your gmail and create a viewable dataframe to see which companies you were rejected from, applied to. As more data is ingested we will be able to increase accuracy as well as identify who Accepted your application as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
